# -*- coding: utf-8 -*-
import sys
import os
import numpy as np
from collections import defaultdict, deque
import time
import random

# === Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¯Ø¹Ù… Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ ===
try:
    # Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠ Windows
    os.system('chcp 65001')
except:
    pass

# Ø¥Ø¹Ø§Ø¯Ø© ØªÙƒÙˆÙŠÙ† Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ Ù„ÙŠØ¯Ø¹Ù… UTF-8
try:
    sys.stdout.reconfigure(encoding='utf-8')
except:
    pass

# Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù…ÙƒØªØ¨Ø§Øª ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ
try:
    import arabic_reshaper
    from bidi.algorithm import get_display
    
    def format_arabic(text):
        """ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ"""
        reshaped = arabic_reshaper.reshape(text)
        return get_display(reshaped)
except ImportError:
    # Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ù…Ø«Ø¨ØªØ©ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù†Øµ ÙƒÙ…Ø§ Ù‡Ùˆ
    def format_arabic(text):
        return text

class IntelligentSecurityAgent:
    def __init__(self, learning_rate=0.1, discount_factor=0.9, exploration_rate=0.2):
        # Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„ØªØ¹Ù„Ù…
        self.learning_rate = learning_rate
        self.discount_factor = discount_factor
        self.exploration_rate = exploration_rate
        
        # ØªØ®Ø²ÙŠÙ† Ø§Ù„ØªØ§Ø±ÙŠØ®
        self.perception_history = deque(maxlen=1000)
        self.action_history = deque(maxlen=1000)
        self.reward_history = deque(maxlen=1000)
        
        # ØªØ¹Ù„Ù… Ø§Ù„Ø£Ù†Ù…Ø§Ø·
        self.ip_behavior_patterns = defaultdict(lambda: defaultdict(int))
        self.protocol_patterns = defaultdict(lambda: defaultdict(int))
        self.threat_patterns = defaultdict(int)
        
        # Ø¬Ø¯ÙˆÙ„ Q-learning
        self.q_table = defaultdict(lambda: defaultdict(float))
        
        # Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© - Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†ØµÙˆØµ Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ù„ØªØ¬Ù†Ø¨ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„ØªØ±Ù…ÙŠØ²
        self.actions = ["MONITOR", "ALERT_ADMIN", "BLOCK_IP"]
        self.threat_states = ["LOW", "MEDIUM", "HIGH", "CRITICAL"]
        
        # Ø§Ù„Ø¹ØªØ¨Ø§Øª Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ©
        self.dynamic_thresholds = {
            'packet_count': 1000,
            'icmp_threshold': 100,
            'connection_rate': 50,
            'suspicious_pattern': 5
        }
        
        # Ø§Ù„Ø¥Ø­ØµØ§Ø¡Ø§Øª
        self.stats = {
            'total_threats_detected': 0,
            'false_positives': 0,
            'learning_improvements': 0,
            'total_decisions': 0
        }

    def perceive(self, network_traffic):
        """Ø§Ø³ØªØ´Ø¹Ø§Ø± Ø§Ù„Ø¨ÙŠØ¦Ø© ÙˆØ¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ"""
        basic_percept = {
            'source_ip': network_traffic['src_ip'],
            'destination_ip': network_traffic['dst_ip'],
            'packet_count': network_traffic['packet_count'],
            'protocol': network_traffic['protocol'],
            'timestamp': time.time()
        }
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ
        historical_context = self._get_historical_context(network_traffic)
        enriched_percept = {**basic_percept, **historical_context}
        
        self.perception_history.append(enriched_percept)
        return enriched_percept

    def _get_historical_context(self, current_traffic):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ Ù„Ù„Ø­Ø±ÙƒØ© Ø§Ù„Ø­Ø§Ù„ÙŠØ©"""
        source_ip = current_traffic['src_ip']
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ù„ÙˆÙƒ Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ Ù„Ù‡Ø°Ø§ IP
        recent_activities = [
            p for p in self.perception_history 
            if p['source_ip'] == source_ip
        ]
        
        # ØªØ¬Ù†Ø¨ Ø§Ù„Ù‚Ø³Ù…Ø© Ø¹Ù„Ù‰ ØµÙØ±
        avg_packet = np.mean([p['packet_count'] for p in recent_activities]) if recent_activities else 1.0
        
        historical_context = {
            'recent_activity_count': len(recent_activities),
            'avg_packet_count': avg_packet,
            'behavior_consistency': self._calculate_behavior_consistency(source_ip),
            'threat_frequency': self._calculate_threat_frequency(source_ip),
            'time_since_last_activity': self._get_time_since_last_activity(source_ip)
        }
        
        return historical_context

    def _calculate_behavior_consistency(self, ip):
        """Ø­Ø³Ø§Ø¨ Ø§ØªØ³Ø§Ù‚ Ø§Ù„Ø³Ù„ÙˆÙƒ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ§Ø±ÙŠØ®"""
        ip_activities = [p for p in self.perception_history if p['source_ip'] == ip]
        if len(ip_activities) < 2:
            return 1.0
            
        packet_counts = [p['packet_count'] for p in ip_activities]
        
        # ØªØ¬Ù†Ø¨ Ø§Ù„Ù‚Ø³Ù…Ø© Ø¹Ù„Ù‰ ØµÙØ±
        if np.mean(packet_counts) == 0:
            return 1.0
            
        consistency = 1.0 / (1.0 + np.std(packet_counts) / np.mean(packet_counts))
        return float(np.clip(consistency, 0, 1))

    def _calculate_threat_frequency(self, ip):
        """Ø­Ø³Ø§Ø¨ ØªÙƒØ±Ø§Ø± Ø§Ù„ØªÙ‡Ø¯ÙŠØ¯Ø§Øª Ù…Ù† IP Ù…Ø¹ÙŠÙ†"""
        threat_count = 0
        for i, action in enumerate(self.action_history):
            if i < len(self.perception_history):
                percept = self.perception_history[i]
                if percept['source_ip'] == ip and action in ["ALERT_ADMIN", "BLOCK_IP"]:
                    threat_count += 1
        return threat_count

    def _get_time_since_last_activity(self, ip):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ÙˆÙ‚Øª Ù…Ù†Ø° Ø¢Ø®Ø± Ù†Ø´Ø§Ø·"""
        ip_activities = [p for p in self.perception_history if p['source_ip'] == ip]
        if not ip_activities:
            return float('inf')
        
        last_activity = max(ip_activities, key=lambda x: x['timestamp'])
        return time.time() - last_activity['timestamp']

    def analyze_threat_with_learning(self, percepts):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ‡Ø¯ÙŠØ¯ Ù…Ø¹ Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„ØªØ§Ø±ÙŠØ®"""
        # Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        base_threat = self._base_threat_analysis(percepts)
        
        # Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø¹Ø²Ø² Ù„Ù„ØªÙ‡Ø¯ÙŠØ¯
        learned_threat = self._reinforcement_learning_analysis(percepts)
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø·
        pattern_threat = self._pattern_based_analysis(percepts)
        
        # Ø§Ù„Ø¬Ù…Ø¹ Ø¨ÙŠÙ† Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª
        combined_threat = self._combine_threat_assessments(base_threat, learned_threat, pattern_threat)
        
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù‚ÙŠÙ…Ø© Ø¨ÙŠÙ† 0-3 ÙˆØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ integer
        return int(np.clip(round(combined_threat), 0, 3))

    def _base_threat_analysis(self, percepts):
        """Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„Ù„ØªÙ‡Ø¯ÙŠØ¯"""
        threat_score = 0
        
        if percepts['packet_count'] > self.dynamic_thresholds['packet_count']:
            threat_score += 2
        
        if percepts['protocol'] == 'ICMP' and percepts['packet_count'] > self.dynamic_thresholds['icmp_threshold']:
            threat_score += 1
        
        if percepts['recent_activity_count'] > self.dynamic_thresholds['connection_rate']:
            threat_score += 1
            
        if percepts['behavior_consistency'] < 0.3:
            threat_score += 1
            
        if percepts['threat_frequency'] > self.dynamic_thresholds['suspicious_pattern']:
            threat_score += 2
            
        return threat_score

    def _reinforcement_learning_analysis(self, percepts):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ‡Ø¯ÙŠØ¯ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø¹Ø²Ø²"""
        state = self._get_state_representation(percepts)
        
        if np.random.random() < self.exploration_rate:
            return random.randint(0, 3)
        else:
            if state in self.q_table and self.q_table[state]:
                return int(max(self.q_table[state].items(), key=lambda x: x[1])[0])
            else:
                return 0

    def _pattern_based_analysis(self, percepts):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ‡Ø¯ÙŠØ¯ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø£Ù†Ù…Ø§Ø· Ø§Ù„ØªØ¹Ù„Ù…"""
        source_ip = percepts['source_ip']
        protocol = percepts['protocol']
        
        # ØªØ¬Ù†Ø¨ Ø§Ù„Ù‚Ø³Ù…Ø© Ø¹Ù„Ù‰ ØµÙØ±
        total_activities = max(len(self.perception_history), 1)
        protocol_score = self.protocol_patterns[source_ip][protocol] / total_activities
        
        avg_packet = max(percepts['avg_packet_count'], 1)  # ØªØ¬Ù†Ø¨ Ø§Ù„Ù‚Ø³Ù…Ø© Ø¹Ù„Ù‰ ØµÙØ±
        packet_anomaly = abs(percepts['packet_count'] - avg_packet) / avg_packet
        
        time_anomaly = 1.0 if percepts['time_since_last_activity'] < 60 else 0.5
        
        threat_score = protocol_score + packet_anomaly + time_anomaly
        return min(threat_score, 3)

    def _get_state_representation(self, percepts):
        """ØªÙ…Ø«ÙŠÙ„ Ø§Ù„Ø­Ø§Ù„Ø© Ù„Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø¹Ø²Ø²"""
        packet_group = int(percepts['packet_count'] / 100)
        activity_group = int(percepts['recent_activity_count'] / 10)
        return f"{percepts['source_ip']}_{percepts['protocol']}_{packet_group}_{activity_group}"

    def _combine_threat_assessments(self, base, learned, pattern):
        """Ø§Ù„Ø¬Ù…Ø¹ Ø¨ÙŠÙ† ØªÙ‚ÙŠÙŠÙ…Ø§Øª Ø§Ù„ØªÙ‡Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©"""
        weights = self._calculate_dynamic_weights()
        combined = (base * weights['base'] + 
                   learned * weights['learned'] + 
                   pattern * weights['pattern'])
        
        return combined

    def _calculate_dynamic_weights(self):
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¯Ù‚Ø© Ø§Ù„ØªØ¹Ù„Ù…"""
        total_decisions = len(self.action_history)
        if total_decisions < 10:
            return {'base': 0.6, 'learned': 0.2, 'pattern': 0.2}
        
        success_rate = self._calculate_learning_success_rate()
        learned_weight = 0.2 + (success_rate * 0.6)
        base_weight = 0.6 - (success_rate * 0.4)
        
        return {'base': base_weight, 'learned': learned_weight, 'pattern': 0.2}

    def _calculate_learning_success_rate(self):
        """Ø­Ø³Ø§Ø¨ Ù…Ø¹Ø¯Ù„ Ù†Ø¬Ø§Ø­ Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„ØªØ§Ø±ÙŠØ®"""
        if len(self.reward_history) < 5:
            return 0.5
            
        positive_rewards = sum(1 for r in self.reward_history if r > 0)
        return positive_rewards / len(self.reward_history)

    def act_with_learning(self, threat_level, percepts):
        """Ø§ØªØ®Ø§Ø° Ø¥Ø¬Ø±Ø§Ø¡ Ù…Ø¹ Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„Ù†ØªØ§Ø¦Ø¬"""
        state = self._get_state_representation(percepts)
        
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† threat_level Ù‡Ùˆ integer
        threat_level = int(threat_level)
        
        # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙ‡Ø¯ÙŠØ¯ ÙˆØ§Ù„ØªØ¹Ù„Ù…
        action_index = self._select_action_based_on_threat(threat_level, state)
        action = self.actions[action_index]
        
        # ØªØ­Ø¯ÙŠØ« Q-table Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ù…Ø®ØªØ§Ø±
        self._update_q_table(state, action_index, threat_level)
        
        self.action_history.append(action)
        self.stats['total_decisions'] += 1
        return action

    def _select_action_based_on_threat(self, threat_level, state):
        """Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙ‡Ø¯ÙŠØ¯"""
        threat_level = int(threat_level)  # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù†Ù‡ integer
        
        if threat_level == 0:  # LOW
            return 0  # MONITOR
        elif threat_level == 1:  # MEDIUM
            return 1  # ALERT_ADMIN
        elif threat_level == 2:  # HIGH
            if state in self.q_table and self.q_table[state]:
                best_action = max(self.q_table[state].items(), key=lambda x: x[1])[0]
                return min(int(best_action), 2)
            else:
                return 1  # ALERT_ADMIN Ø§ÙØªØ±Ø§Ø¶ÙŠ
        else:  # CRITICAL (3)
            return 2  # BLOCK_IP

    def _calculate_reward(self, action_index, threat_level):
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ÙƒØ§ÙØ£Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ù†Ø§Ø³Ø¨Ø© Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙ‡Ø¯ÙŠØ¯"""
        action_severity = int(action_index)
        threat_level = int(threat_level)
        
        optimal_match = threat_level == action_severity
        over_reaction = action_severity > threat_level
        under_reaction = action_severity < threat_level
        
        if optimal_match:
            return 1.0
        elif over_reaction:
            return -0.5
        elif under_reaction:
            return -1.0
        else:
            return 0.0

    def _update_q_table(self, state, action_index, threat_level):
        """ØªØ­Ø¯ÙŠØ« Ø¬Ø¯ÙˆÙ„ Q-learning"""
        reward = self._calculate_reward(action_index, threat_level)
        self.reward_history.append(reward)
        
        current_q = self.q_table[state][action_index]
        max_future_q = max(self.q_table[state].values()) if self.q_table[state] else 0
        
        new_q = current_q + self.learning_rate * (reward + self.discount_factor * max_future_q - current_q)
        self.q_table[state][action_index] = new_q

    def learn_from_feedback(self, percepts, action_taken, was_correct):
        """Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©"""
        threat_level = self.analyze_threat_with_learning(percepts)
        state = self._get_state_representation(percepts)
        action_index = self.actions.index(action_taken)
        
        if was_correct:
            reward = 2.0
            self.stats['learning_improvements'] += 1
        else:
            reward = -2.0
            self.stats['false_positives'] += 1
        
        # ØªØ­Ø¯ÙŠØ« Ù…Ø¨Ø§Ø´Ø± Ù„Ù€ Q-table Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø©
        current_q = self.q_table[state][action_index]
        self.q_table[state][action_index] = current_q + self.learning_rate * reward
        
        self._update_dynamic_thresholds(was_correct)

    def _update_dynamic_thresholds(self, was_correct):
        """ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¹ØªØ¨Ø§Øª Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        if was_correct:
            self.dynamic_thresholds['packet_count'] = max(500, self.dynamic_thresholds['packet_count'] - 10)
        else:
            self.dynamic_thresholds['packet_count'] = min(2000, self.dynamic_thresholds['packet_count'] + 50)

    def get_learning_stats(self):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ¹Ù„Ù…"""
        return {
            'total_decisions': self.stats['total_decisions'],
            'learning_success_rate': self._calculate_learning_success_rate(),
            'recent_positive_rewards': sum(1 for r in list(self.reward_history)[-10:] if r > 0),
            'dynamic_thresholds': self.dynamic_thresholds.copy(),
            'performance_stats': self.stats.copy(),
            'q_table_size': len(self.q_table),
            'memory_usage': len(self.perception_history)
        }

    def _calculate_confidence(self):
        """Ø­Ø³Ø§Ø¨ Ø«Ù‚Ø© Ø§Ù„ÙˆÙƒÙŠÙ„ ÙÙŠ Ù‚Ø±Ø§Ø±Ø§ØªÙ‡"""
        if len(self.reward_history) < 5:
            return 0.5
            
        recent_rewards = list(self.reward_history)[-10:]
        if not recent_rewards:
            return 0.5
            
        positive_ratio = sum(1 for r in recent_rewards if r > 0) / len(recent_rewards)
        return positive_ratio

    def run_intelligent_agent(self, network_traffic, feedback=None):
        """ØªØ´ØºÙŠÙ„ Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„ÙƒØ§Ù…Ù„"""
        # 1. Ø§Ù„Ø¥Ø¯Ø±Ø§Ùƒ Ù…Ø¹ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ
        percepts = self.perceive(network_traffic)
        
        # 2. Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù…Ø¹ Ø§Ù„ØªØ¹Ù„Ù… - Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† threat_level Ù‡Ùˆ integer
        threat_level = self.analyze_threat_with_learning(percepts)
        threat_level = int(threat_level)  # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ integer
        
        # 3. Ø§ØªØ®Ø§Ø° Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ù…Ø¹ Ø§Ù„ØªØ¹Ù„Ù…
        action = self.act_with_learning(threat_level, percepts)
        
        # 4. Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø© Ø¥Ø°Ø§ ÙˆØ¬Ø¯Øª
        if feedback is not None:
            self.learn_from_feedback(percepts, action, feedback)
            self.stats['total_threats_detected'] += 1
        
        return {
            'action': action,
            'threat_level': self.threat_states[threat_level],  # Ø§Ù„Ø¢Ù† threat_level integer
            'threat_score': threat_level,
            'confidence': self._calculate_confidence(),
            'learning_stats': self.get_learning_stats(),
            'historical_context': {
                'recent_activities': percepts['recent_activity_count'],
                'behavior_consistency': round(percepts['behavior_consistency'], 2),
                'threat_frequency': percepts['threat_frequency'],
                'avg_packet_count': round(percepts['avg_packet_count'], 2)
            }
        }

# Ù…Ø­Ø§ÙƒÙŠ Ø­Ø±ÙƒØ© Ø§Ù„Ù…Ø±ÙˆØ±
class NetworkTrafficSimulator:
    def __init__(self):
        self.normal_ips = ['192.168.1.10', '192.168.1.11', '192.168.1.12']
        self.suspicious_ips = ['10.0.0.100', '10.0.0.101']
        self.protocols = ['TCP', 'UDP', 'ICMP', 'HTTP']
        
    def generate_normal_traffic(self):
        return {
            'src_ip': random.choice(self.normal_ips),
            'dst_ip': f'10.0.0.{random.randint(1, 50)}',
            'packet_count': random.randint(1, 100),
            'protocol': random.choice(self.protocols)
        }
    
    def generate_suspicious_traffic(self):
        traffic_type = random.choice(['ddos', 'scan', 'flood'])
        
        if traffic_type == 'ddos':
            return {
                'src_ip': random.choice(self.suspicious_ips),
                'dst_ip': '10.0.0.1',
                'packet_count': random.randint(1000, 5000),
                'protocol': 'TCP'
            }
        elif traffic_type == 'scan':
            return {
                'src_ip': random.choice(self.suspicious_ips),
                'dst_ip': f'10.0.0.{random.randint(1, 255)}',
                'packet_count': random.randint(150, 300),
                'protocol': 'ICMP'
            }
        else:  # flood
            return {
                'src_ip': random.choice(self.suspicious_ips),
                'dst_ip': f'10.0.0.{random.randint(1, 10)}',
                'packet_count': random.randint(800, 2000),
                'protocol': random.choice(['UDP', 'TCP'])
            }

# Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„ÙƒØ§Ù…Ù„
if __name__ == "__main__":
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ù…Ø¹ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚
    print(format_arabic("=== Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ù…Ù†ÙŠ Ø§Ù„Ø°ÙƒÙŠ ==="))
    print()
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙˆÙƒÙŠÙ„ ÙˆØ§Ù„Ù…Ø­Ø§ÙƒÙŠ
    smart_agent = IntelligentSecurityAgent()
    simulator = NetworkTrafficSimulator()
    
    # Ø¹Ø¯Ø¯ Ø¯ÙˆØ±Ø§Øª Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø©
    simulation_cycles = 20
    
    print(format_arabic("Ù…Ø­Ø§ÙƒØ§Ø© Ø­Ø±ÙƒØ© Ù…Ø±ÙˆØ± Ø§Ù„Ø´Ø¨ÙƒØ©..."))
    print("-" * 60)
    
    for cycle in range(simulation_cycles):
        print(format_arabic(f"\n--- Ø§Ù„Ø¯ÙˆØ±Ø© {cycle + 1} ---"))
        
        # ØªÙˆÙ„ÙŠØ¯ Ø­Ø±ÙƒØ© Ù…Ø±ÙˆØ± (80% Ø¹Ø§Ø¯ÙŠØ©ØŒ 20% Ù…Ø´Ø¨ÙˆÙ‡Ø©)
        if random.random() < 0.8:
            traffic = simulator.generate_normal_traffic()
            actual_threat = False
        else:
            traffic = simulator.generate_suspicious_traffic()
            actual_threat = True
        
        print(f"Ø­Ø±ÙƒØ© Ø§Ù„Ù…Ø±ÙˆØ±: {traffic}")
        
        # Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø©
        feedback = actual_threat if random.random() < 0.9 else not actual_threat
        
        # ØªØ´ØºÙŠÙ„ Ø§Ù„ÙˆÙƒÙŠÙ„
        result = smart_agent.run_intelligent_agent(traffic, feedback)
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ
        print(format_arabic(f"â†’ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡: {result['action']}"))
        print(format_arabic(f"â†’ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙ‡Ø¯ÙŠØ¯: {result['threat_level']} (Ø¯Ø±Ø¬Ø©: {result['threat_score']})"))
        print(format_arabic(f"â†’ Ø§Ù„Ø«Ù‚Ø©: {result['confidence']:.2f}"))
        print(format_arabic(f"â†’ Ø§Ù„Ø³ÙŠØ§Ù‚: {result['historical_context']}"))
        
        # Ø¹Ø±Ø¶ Ø§Ù„ØªÙ‚Ø¯Ù… ÙÙŠ Ø§Ù„ØªØ¹Ù„Ù… ÙƒÙ„ 5 Ø¯ÙˆØ±Ø§Øª
        if (cycle + 1) % 5 == 0:
            stats = result['learning_stats']
            print(format_arabic(f"\nğŸ“Š ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ¹Ù„Ù… Ø¨Ø¹Ø¯ {cycle + 1} Ø¯ÙˆØ±Ø©:"))
            print(format_arabic(f"   - Ø§Ù„Ù‚Ø±Ø§Ø±Ø§Øª Ø§Ù„ÙƒÙ„ÙŠØ©: {stats['total_decisions']}"))
            print(format_arabic(f"   - Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­: {stats['learning_success_rate']:.2f}"))
            print(format_arabic(f"   - Ø§Ù„Ù…ÙƒØ§ÙØ¢Øª Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ© Ø§Ù„Ø£Ø®ÙŠØ±Ø©: {stats['recent_positive_rewards']}/10"))
            print(format_arabic(f"   - Ø¹ØªØ¨Ø© Ø§Ù„Ø­Ø²Ù…: {stats['dynamic_thresholds']['packet_count']}"))
            print(format_arabic(f"   - Ø­Ø¬Ù… Ø°Ø§ÙƒØ±Ø© Q: {stats['q_table_size']} Ø­Ø§Ù„Ø©"))
    
    print("\n" + "=" * 60)
    print(format_arabic("=== Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ==="))
    
    final_stats = smart_agent.get_learning_stats()
    
    print(format_arabic("\nØ¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡:"))
    for stat_key, stat_value in final_stats['performance_stats'].items():
        print(format_arabic(f"  - {stat_key}: {stat_value}"))
    
    print(format_arabic("\nØ§Ù„Ø¹ØªØ¨Ø§Øª Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©:"))
    for threshold_key, threshold_value in final_stats['dynamic_thresholds'].items():
        print(format_arabic(f"  - {threshold_key}: {threshold_value}"))
    
    print(format_arabic("\nØ®Ù„Ø§ØµØ© Ø£Ø¯Ø§Ø¡ Ø§Ù„ÙˆÙƒÙŠÙ„:"))
    total_decisions = final_stats['performance_stats']['total_decisions']
    learning_improvements = final_stats['performance_stats']['learning_improvements']
    false_positives = final_stats['performance_stats']['false_positives']
    
    if total_decisions > 0:
        improvement_rate = (learning_improvements / total_decisions) * 100
        false_positive_rate = (false_positives / total_decisions) * 100
        
        print(format_arabic(f"Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ­Ø³Ù†: {improvement_rate:.1f}%"))
        print(format_arabic(f"Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¥Ù†Ø°Ø§Ø±Ø§Øª Ø§Ù„ÙƒØ§Ø°Ø¨Ø©: {false_positive_rate:.1f}%"))
        print(format_arabic(f"Ù…Ø¹Ø¯Ù„ Ù†Ø¬Ø§Ø­ Ø§Ù„ØªØ¹Ù„Ù…: {final_stats['learning_success_rate']:.1%}"))
    
    print(format_arabic("\nğŸ¯ Ø§Ù„Ù†Ø¸Ø§Ù… Ø¬Ø§Ù‡Ø² Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙŠ Ø¨ÙŠØ¦Ø© Ø­Ù‚ÙŠÙ‚ÙŠØ©!"))